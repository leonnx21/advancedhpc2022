{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Rg2914FgUkcw"},"outputs":[],"source":["from numba import cuda\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import time\n","import math\n","from PIL import Image"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27171,"status":"ok","timestamp":1673179941122,"user":{"displayName":"Xuan Loc Nguyen","userId":"10556902414344061933"},"user_tz":-420},"id":"BK4X7Cj8U2tu","outputId":"abce6c9b-aa64-4028-91b7-f21782ac10ec"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Anz5jcgU4lE"},"outputs":[],"source":["im = plt.imread(\"/content/drive/MyDrive/Colab Notebooks/image1.jpg\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1673179941845,"user":{"displayName":"Xuan Loc Nguyen","userId":"10556902414344061933"},"user_tz":-420},"id":"hylCwBTqVFJO","outputId":"7640ee15-1a43-4373-f595-057330f2f0d8"},"outputs":[{"data":{"text/plain":["(1080, 1920, 3)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["shape = np.shape(im)\n","shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"es9VRMCUlyow"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3a8RErgLw8xl"},"outputs":[],"source":["@cuda.jit\n","def HSVconversion(input, hsv):\n","  local_tidx = cuda.threadIdx.x\n","  local_tidy = cuda.threadIdx.y\n","\n","  tidx = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n","  tidy = cuda.threadIdx.y + cuda.blockIdx.y * cuda.blockDim.y\n","\n","  shared_memory = cuda.shared.array(shape=(8, 8, 3), dtype=np.uint8)\n","  \n","  if local_tidx < input.shape[0] and local_tidy < input.shape[1]:\n","    shared_memory[local_tidx, local_tidy, 0] = input[tidx, tidy, 0]\n","    shared_memory[local_tidx, local_tidy, 1] = input[tidx, tidy, 1]\n","    shared_memory[local_tidx, local_tidy, 2] = input[tidx, tidy, 2]\n","  \n","  cuda.syncthreads()\n","\n","  R = shared_memory[local_tidx, local_tidy, 0]/255\n","  G = shared_memory[local_tidx, local_tidy, 1]/255\n","  B = shared_memory[local_tidx, local_tidy, 2]/255\n","\n","  Max = max(R,G,B)\n","\n","  hsv[tidx, tidy, 0] = Max\n","  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mCRIjii0zDIO"},"outputs":[],"source":["@cuda.jit\n","def addpadding(input, output, omega):\n","  local_tidx = cuda.threadIdx.x\n","  local_tidy = cuda.threadIdx.y\n","\n","  tidx = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n","  tidy = cuda.threadIdx.y + cuda.blockIdx.y * cuda.blockDim.y\n","\n","  shared_memory = cuda.shared.array(shape=(8, 8, 1), dtype=np.float64)\n","  \n","  if local_tidx < input.shape[0] and local_tidy < input.shape[1]:\n","    shared_memory[local_tidx, local_tidy, 0] = input[tidx, tidy, 0]\n","\n","  cuda.syncthreads()\n","\n","  if (tidx < omega) or (tidy < omega) or (tidx > input.shape[0]+(omega)) or (tidy > input.shape[1]+(omega)):\n","    return\n","\n","  output[(tidx+omega), (tidy+omega), 0] = shared_memory[local_tidx, local_tidy, 0]\n"," \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LcEwtUC-zFrR"},"outputs":[],"source":["@cuda.jit\n","def generatewindow(hsvinput, omega, shapeimage, output):\n","  local_tidx = cuda.threadIdx.x\n","  local_tidy = cuda.threadIdx.y\n","\n","  tidx = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n","  tidy = cuda.threadIdx.y + cuda.blockIdx.y * cuda.blockDim.y\n","\n","  shared_memory = cuda.shared.array(shape=(16, 16, 1), dtype=np.float64)\n","  \n","  if (tidx < omega) or (tidy < omega) or (tidx > shapeimage[0]+(omega)) or (tidy > shapeimage[1]+(omega)):\n","    return\n","\n","  if local_tidx < hsvinput.shape[0] and local_tidy < hsvinput.shape[1]:\n","    shared_memory[local_tidx, local_tidy, 0] = hsvinput[tidx-4, tidy-4, 0]\n","    shared_memory[local_tidx+8, local_tidy, 0] = hsvinput[tidx+4, tidy-4, 0]\n","    shared_memory[local_tidx, local_tidy+8, 0] = hsvinput[tidx-4, tidy+4, 0]\n","    shared_memory[local_tidx+8, local_tidy+8, 0] = hsvinput[tidx+4, tidy+4, 0]\n","\n","  cuda.syncthreads()\n","  \n","  # if (tidx < omega) or (tidy < omega) or (tidx > shapeimage[0]+(omega)) or (tidy > shapeimage[1]+(omega)):\n","  #   return\n","\n","  # if (local_tidx < omega) or (local_tidy < omega) or (local_tidx > 8+(omega)) or (local_tidy > 8+(omega)):\n","  #   return\n","\n","  count = 0\n","  for wx in range(0, omega+1):\n","    for wy in range(0, omega+1):\n","      w1 = shared_memory[local_tidx+omega-wx,local_tidy+omega-wy,0]\n","      w2 = shared_memory[local_tidx+omega+wx,local_tidy+omega-wy,0]\n","      w3 = shared_memory[local_tidx+omega-wx,local_tidy+omega+wy,0]\n","      w4 = shared_memory[local_tidx+omega+wx,local_tidy+omega+wy,0]\n","\n","      output[tidx,tidy,0,count] = w1 \n","      output[tidx,tidy,1,count] = w2\n","      output[tidx,tidy,2,count] = w3\n","      output[tidx,tidy,3,count] = w4\n","       \n","      count += 1\n","\n","  cuda.syncthreads()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oq0A8-nxzGT9"},"outputs":[],"source":["@cuda.jit\n","def calstd(input, omega, output):\n","  local_tidx = cuda.threadIdx.x\n","  local_tidy = cuda.threadIdx.y\n","\n","  tidx = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n","  tidy = cuda.threadIdx.y + cuda.blockIdx.y * cuda.blockDim.y\n","\n","  shared_memory = cuda.shared.array(shape=(4, 4, 4, 25), dtype=np.float64)\n","\n","  size = (omega+1)**2\n","\n","  if (tidx < omega) or (tidy < omega) or (tidx > shape[0]+omega) or (tidy > shape[1]+omega):\n","    return\n","\n","  if local_tidx < input.shape[0] and local_tidy < input.shape[1]:\n","    for i in range(4):\n","      for j in range(size):\n","        shared_memory[local_tidx, local_tidy,i,j] = input[tidx, tidy,i,j]\n","\n","  cuda.syncthreads()\n","\n","  w0 = shared_memory[local_tidx, local_tidy,0]\n","  w1 = shared_memory[local_tidx, local_tidy,1]\n","  w2 = shared_memory[local_tidx, local_tidy,2]\n","  w3 = shared_memory[local_tidx, local_tidy,3]\n","\n","  #Window 0\n","  t = 0\n","  for i in w0:\n","    t = t + i\n","  mean0 = t/size\n","\n","  t2 = 0 \n","  for i in w0:\n","    t2 = t2 + (i- mean0)**2\n","  \n","  std0 = math.sqrt(t2/size)\n","\n","  #Window 1\n","  t = 0\n","  for i in w1:\n","    t = t + i\n","  mean1 = t/size\n","\n","  t2 = 0 \n","  for i in w1:\n","    t2 = t2 + (i- mean1)**2\n","\n","  std1 = math.sqrt(t2/size)\n","\n","  #Window 2\n","  t = 0\n","  for i in w2:\n","    t = t + i\n","  mean2 = t/size\n","\n","  t2 = 0 \n","  for i in w2:\n","    t2 = t2 + (i- mean2)**2\n","\n","  std2 = math.sqrt(t2/size)\n","\n","  #Window 3\n","  t = 0\n","  for i in w3:\n","    t = t + i\n","  mean3 = t/size\n","\n","  t2 = 0 \n","  for i in w3:\n","    t2 = t2 + (i- mean3)**2\n","\n","  std3 = math.sqrt(t2/size)\n","\n","  # minstd = min(std0, std1, std2, std3)\n","  \n","  minstd = 1\n","  for i in (std0,std1,std2,std3):\n","    if i < minstd:\n","      minstd = i\n","\n","  if minstd == std0:\n","    output[tidx, tidy, 0] = 0\n","  elif minstd == std1:\n","    output[tidx, tidy, 0] = 1\n","  elif minstd == std2:\n","    output[tidx, tidy, 0] = 2\n","  elif minstd == std3:\n","    output[tidx, tidy, 0] = 3\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SDmwAzxhzJcF"},"outputs":[],"source":["@cuda.jit\n","def addpadding2(input, output, omega):\n","  local_tidx = cuda.threadIdx.x\n","  local_tidy = cuda.threadIdx.y\n","\n","  tidx = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n","  tidy = cuda.threadIdx.y + cuda.blockIdx.y * cuda.blockDim.y\n","\n","  shared_memory = cuda.shared.array(shape=(8, 8, 3), dtype=np.uint8)\n","  \n","  if local_tidx < input.shape[0] and local_tidy < input.shape[1]:\n","    shared_memory[local_tidx, local_tidy, 0] = input[tidx, tidy, 0]\n","    shared_memory[local_tidx, local_tidy, 1] = input[tidx, tidy, 1]\n","    shared_memory[local_tidx, local_tidy, 2] = input[tidx, tidy, 2]\n","\n","  cuda.syncthreads()\n","\n","  if (tidx < omega) or (tidy < omega) or (tidx > shape[0]+(omega)) or (tidy > shape[1]+(omega)):\n","    return\n","\n","  output[(tidx+omega), (tidy+omega), 0] = shared_memory[local_tidx, local_tidy, 0]\n","  output[(tidx+omega), (tidy+omega), 1] = shared_memory[local_tidx, local_tidy, 1]\n","  output[(tidx+omega), (tidy+omega), 2] = shared_memory[local_tidx, local_tidy, 2]\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AXzv8GB7zN5y"},"outputs":[],"source":["@cuda.jit\n","def kuwahara(input, stdwindow, shapeimage, omega, output):\n","  local_tidx = cuda.threadIdx.x\n","  local_tidy = cuda.threadIdx.y\n","\n","  tidx = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n","  tidy = cuda.threadIdx.y + cuda.blockIdx.y * cuda.blockDim.y\n","\n","  shared_memory = cuda.shared.array(shape=(16, 16, 3), dtype=np.uint8)\n","\n","  if (tidx < omega) or (tidy < omega) or (tidx > shapeimage[0]+(omega)) or (tidy > shapeimage[1]+(omega)):\n","    return\n","\n","  if local_tidx < input.shape[0] and local_tidy < input.shape[1]:\n","    shared_memory[local_tidx, local_tidy, 0] = input[tidx-4, tidy-4, 0]\n","    shared_memory[local_tidx, local_tidy, 1] = input[tidx-4, tidy-4, 1]\n","    shared_memory[local_tidx, local_tidy, 2] = input[tidx-4, tidy-4, 2]\n","\n","    shared_memory[local_tidx+8, local_tidy, 0] = input[tidx+4, tidy-4, 0]\n","    shared_memory[local_tidx+8, local_tidy, 1] = input[tidx+4, tidy-4, 1]\n","    shared_memory[local_tidx+8, local_tidy, 2] = input[tidx+4, tidy-4, 2]\n","\n","    shared_memory[local_tidx, local_tidy+8, 0] = input[tidx-4, tidy+4, 0]\n","    shared_memory[local_tidx, local_tidy+8, 1] = input[tidx-4, tidy+4, 1]\n","    shared_memory[local_tidx, local_tidy+8, 2] = input[tidx-4, tidy+4, 2]\n","\n","    shared_memory[local_tidx+8, local_tidy+8, 0] = input[tidx+4, tidy+4, 0]\n","    shared_memory[local_tidx+8, local_tidy+8, 1] = input[tidx+4, tidy+4, 1]\n","    shared_memory[local_tidx+8, local_tidy+8, 2] = input[tidx+4, tidy+4, 2]\n","\n","\n","  cuda.syncthreads()\n","\n","  size = (omega+1)**2\n","\n","  # if (local_tidx < omega) or (local_tidy < omega) or (local_tidx > 8+(omega)) or (local_tidy > 8+(omega)):\n","  #   return\n","\n","\n","  Rtotal = 0\n","  Gtotal = 0\n","  Btotal = 0\n","  for wx in range(omega+1):\n","     for wy in range(omega+1):\n","        if stdwindow[tidx, tidy,0]==0:\n","          Rtotal += shared_memory[local_tidx+omega-wx,local_tidy+omega-wy,0]\n","          Gtotal += shared_memory[local_tidx+omega-wx,local_tidy+omega-wy,1]\n","          Btotal += shared_memory[local_tidx+omega-wx,local_tidy+omega-wy,2]\n","\n","          output[tidx, tidy, 0] = Rtotal/size\n","          output[tidx, tidy, 1] = Gtotal/size\n","          output[tidx, tidy, 2] = Btotal/size\n","       \n","        elif stdwindow[tidx, tidy,0]==1:\n","          Rtotal += shared_memory[local_tidx+omega+wx,local_tidy+omega-wy,0]\n","          Gtotal += shared_memory[local_tidx+omega+wx,local_tidy+omega-wy,1]\n","          Btotal += shared_memory[local_tidx+omega+wx,local_tidy+omega-wy,2]\n","\n","          output[tidx, tidy, 0] = Rtotal/size\n","          output[tidx, tidy, 1] = Gtotal/size\n","          output[tidx, tidy, 2] = Btotal/size  \n","\n","        elif stdwindow[tidx, tidy,0]==2:\n","          Rtotal += shared_memory[local_tidx+omega-wx,local_tidy+omega+wy,0]\n","          Gtotal += shared_memory[local_tidx+omega-wx,local_tidy+omega+wy,1]\n","          Btotal += shared_memory[local_tidx+omega-wx,local_tidy+omega+wy,2]\n","\n","          output[tidx, tidy, 0] = Rtotal/size\n","          output[tidx, tidy, 1] = Gtotal/size\n","          output[tidx, tidy, 2] = Btotal/size\n","\n","        elif stdwindow[tidx, tidy,0]==3:\n","          Rtotal += shared_memory[local_tidx+omega+wx,local_tidy+omega+wy,0]\n","          Gtotal += shared_memory[local_tidx+omega+wx,local_tidy+omega+wy,1]\n","          Btotal += shared_memory[local_tidx+omega+wx,local_tidy+omega+wy,2]\n","\n","          output[tidx, tidy, 0] = Rtotal/size\n","          output[tidx, tidy, 1] = Gtotal/size\n","          output[tidx, tidy, 2] = Btotal/size\n","        \n","        # else:\n","        #   output[tidx, tidy, 0] = input[tidx, tidy, 0]\n","        #   output[tidx, tidy, 1] = input[tidx, tidy, 1]\n","        #   output[tidx, tidy, 2] = input[tidx, tidy, 2]\n","\n","  cuda.syncthreads()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2jV6D-8o0Rnd"},"outputs":[],"source":["blockSize = (8,8)\n","gridSize = (math.ceil(shape[0]/blockSize[0]),math.ceil(shape[1]/blockSize[1]))\n","omega = 4\n","image = cuda.to_device(im)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3168,"status":"ok","timestamp":1673179946127,"user":{"displayName":"Xuan Loc Nguyen","userId":"10556902414344061933"},"user_tz":-420},"id":"s9ZXdhAazcW5","outputId":"b6c165ce-ba4e-46c4-80f7-ca9bbc780dfc"},"outputs":[{"name":"stdout","output_type":"stream","text":["3.113365411758423\n"]}],"source":["t1 = time.time()\n","\n","#conversion of RGB to HSV\n","hsvdev1 = cuda.device_array((shape[0],shape[1],1), np.float64)\n","HSVconversion[gridSize, blockSize](image, hsvdev1)\n","\n","#add padding to HSV image\n","hsvdev2 = cuda.device_array((shape[0]+omega*2,shape[1]+omega*2,1), np.float64)\n","addpadding[gridSize, blockSize](hsvdev1, hsvdev2, omega)\n","\n","#add generate window information\n","windowdev = cuda.device_array((shape[0]+omega*2,shape[1]+omega*2,4,(omega+1)**2), np.float64)\n","generatewindow[gridSize, blockSize](hsvdev2, omega, shape, windowdev)\n","\n","#calclate STD and find lowest STD window\n","blockSize1 = (4,4)\n","gridSize1 = (math.ceil(shape[0]/blockSize1[0]),math.ceil(shape[1]/blockSize1[1]))\n","stdwindow = cuda.device_array((shape[0]+omega*2,shape[1]+omega*2,1), np.int8)\n","calstd[gridSize1, blockSize1](windowdev, omega, stdwindow)\n","\n","#add padding to RGB image\n","impadded = cuda.device_array((shape[0]+omega*2,shape[1]+omega*2,3), np.uint8)\n","addpadding2[gridSize, blockSize](image, impadded, omega)\n","\n","#apply filter\n","outputimage = cuda.device_array((shape[0]+omega*2,shape[1]+omega*2,3), np.uint8)\n","kuwahara[gridSize, blockSize](impadded, stdwindow, shape, omega, outputimage)\n","\n","t2 = time.time()\n","print(t2-t1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1Cz2xRu01RCwVHSZivnOPOKuPl0RU8Dkh"},"executionInfo":{"elapsed":14825,"status":"ok","timestamp":1673179960948,"user":{"displayName":"Xuan Loc Nguyen","userId":"10556902414344061933"},"user_tz":-420},"id":"uFK9wQNQzfA-","outputId":"0343d58d-0bab-4149-ae0f-1690d723d66e"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["outputimagehost = outputimage.copy_to_host()\n","imgpu = Image.fromarray(outputimagehost)\n","imgpu"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"eaQ2jKb6gtrs"},"outputs":[],"source":["imgpu.save(\"/content/drive/MyDrive/Colab Notebooks/kuwaharafilter_sharedmemGPU.jpeg\")"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}